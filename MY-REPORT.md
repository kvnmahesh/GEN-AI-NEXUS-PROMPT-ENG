# Automating Requirement Analysis for Study Companion Bot (GEN AI NEXUS)

![GenI-Banner](https://github.com/genilab-fau/genial-fau.github.io/blob/8f1a2d3523f879e1082918c7bba19553cb6e7212/images/geni-lab-banner.png?raw=true)

## 1-liner Description
Developing an automated Requirement Analysis process for the study companion bot, GEN AI NEXUS, using advanced Prompt Engineering techniques.

### Authors
- [Kunapaneni Venkata Naga Mahesh](http://www.YOURPAGE.xxx)
- [Rajeev Pondala](http://www.YOURPAGE.xxx)
- [Sindhuja Lakkapally](http://www.YOURPAGE.xxx)

### Academic Supervisor
- [Dr. Fernando Koch](http://www.fernandokoch.me)

---

## Research Question
What is the most effective configuration of Prompt Engineering techniques to automate Requirement Analysis in the SDLC using GEN AI NEXUS?

---

## Arguments

### What is already known about this topic
- **Prompt Engineering Benefits:** Automates data gathering and synthesis during Requirement Analysis.
- **Challenges:** Automation must not hinder creative and critical thinking, crucial in early SDLC stages.
- **Balanced Approach:** Combining manual and automated techniques can improve quality.

### What this research is exploring
- Utilizing advanced Prompt Engineering techniques:
  - **Zero-Shot Prompting:** Generating requirements without prior examples.
  - **Few-Shot Prompting:** Providing a few examples to guide the bot.
  - **Prompt Templates:** Standardized prompts for consistency.
  - **Chain-of-Thought Prompting:** Enabling step-by-step reasoning.

- Building **GEN AI NEXUS** to assist students with personalized tutoring.
- Automating **Requirement Analysis** in the **SDLC** to save time and enhance accuracy.

### Implications for practice
- Simplifies Requirement Analysis for educational software.
- Accelerates early-stage software development processes.
- Provides insights into how automation impacts project efficiency.

---

## Research Method
- Developing a **GEN AI NEXUS prototype** using the **Prompt Engineering Lab**.
- Testing various prompting techniques:
  - Example: Using **Few-Shot Prompting** to generate requirements for a new tutoring feature.
- Evaluating the accuracy and relevance of generated requirements.
- Comparing manual vs. automated methods for efficiency.

---

## Results
- **Best Performance:** Combining **Chain-of-Thought** with **Automated Prompt Generation** yielded the highest accuracy.
- **Impact on GEN AI NEXUS:** The bot generated more detailed and relevant requirements.
- **Example:** When asked to create requirements for a “Quiz Module,” the bot produced structured outputs like:
  - “The bot should generate quizzes based on the student's current topic.”
  - “Quizzes should adapt to the student’s learning pace.”

---

## Further Research
- Integrate **GEN AI NEXUS** with additional **GenAI models**.
- Extend automation to **Solution Design** and **Development** phases of the **SDLC**.
- Explore **dynamic prompting** where the bot adjusts prompts based on previous interactions.
